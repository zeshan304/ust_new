{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropogation\n",
    "- Training a network  (backpropagation) consists of:\n",
    "  - Initializing weights at “random”.\n",
    "  - Compute the network forward (forward pass)\n",
    "  - Reduce loss by updating weights in opposite direction of gradient of the loss function.\n",
    "  - Repeat the process until an optimized set of weights are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/backprop.png\" height=\"600\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent\n",
    "<img src=\"img/sgd2d.png\" width=\"480\" height=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loss Function\n",
    "<img src=\"img/loss.png\" height=\"480\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Non-Convex Optimization\n",
    "<img src=\"img/nonconvex.png\" height=\"720\" width=\"720\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a network\n",
    "- Define the network\n",
    "- Initialize the network with with random/pre-trained weights\n",
    "- Choose a loss function\n",
    "- Choose an optimizer\n",
    "- Prepare Dataset\n",
    "- Run back propogation algorithm.\n",
    "- Evaluate the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd\n",
    "import numpy as np\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = gluon.nn.Sequential()\n",
    "\n",
    "with net.name_scope(): #Returns a name space object managing a child :py:class:`Block` and parameter names.\n",
    "    net.add(gluon.nn.Dense(units=128, activation='relu'))\n",
    "    net.add(gluon.nn.Dense(units=64, activation='relu'))\n",
    "    net.add(gluon.nn.Dense(units=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net.initialize(mx.init.Xavier(magnitude=2.24), force_reinit=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choose a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choose an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(params=net.collect_params(), \n",
    "                        optimizer='sgd', \n",
    "                        optimizer_params={\"learning_rate\":0.01, \"momentum\": .9, \"wd\":.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1), 5.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "def transform(data, label):\n",
    "    return (data.astype(np.float32)/255, label.astype(np.float32))\n",
    "\n",
    "train_dataset = gluon.data.vision.MNIST(train=True, transform=transform)\n",
    "val_dataset = gluon.data.vision.MNIST(train=False, transform=transform)\n",
    "\n",
    "train_data_loader = gluon.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = gluon.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "(train_dataset[0][0].shape, train_dataset[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_labels = [\n",
    "    'zero', 'one', 'two', 'three', 'four',\n",
    "    'five', 'six', 'seven', 'eight', 'nine'\n",
    "]\n",
    "X, y = train_dataset[0:6]\n",
    "_, figs = plt.subplots(1, X.shape[0], figsize=(15, 15))\n",
    "for f,x,yi in zip(figs, X,y):\n",
    "    # 3D->2D by removing the last channel dim\n",
    "    f.imshow(x.reshape((28,28)).asnumpy())\n",
    "    ax = f.axes\n",
    "    ax.set_title(text_labels[int(yi)])\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1), 5.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataset[0][0].shape, train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1) (128,)\n"
     ]
    }
   ],
   "source": [
    "for data, label in train_data_loader:\n",
    "    print(data.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Run back propogation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOC: [0]: ; train loss: 0.9659042954444885\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data_loader):\n",
    "        with autograd.record():\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            outputs = net(data)\n",
    "            loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "    print(\"EPOC: [{}]: ; train loss: {}\".format(e, loss.mean().asscalar()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluate the Output\n",
    "- In order to evaluate the putput we need to compare performance of the algorithm on training and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_results(data_loader, network):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    \n",
    "    metric.reset()\n",
    "    for i, (data, label) in enumerate(data_loader):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        outputs = network(data)\n",
    "        predictions = nd.argmax(outputs, axis=1)\n",
    "        metric.update(preds=predictions, labels=label)\n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [0]: ; train loss: 0.8281387686729431; train_acc: 0.8087166666666666; val_acc: 0.817\n",
      "EPOCH: [1]: ; train loss: 0.7974648475646973; train_acc: 0.8083833333333333; val_acc: 0.8146\n",
      "EPOCH: [2]: ; train loss: 0.9794893264770508; train_acc: 0.8111666666666667; val_acc: 0.8178\n",
      "EPOCH: [3]: ; train loss: 0.768927276134491; train_acc: 0.8066; val_acc: 0.8135\n",
      "EPOCH: [4]: ; train loss: 0.8989737033843994; train_acc: 0.8082666666666667; val_acc: 0.8135\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data_loader):\n",
    "        with autograd.record():\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            outputs = net(data)\n",
    "            loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "    train_acc = evaluate_results(train_data_loader, net).get()[1]\n",
    "    val_acc = evaluate_results(val_data_loader, net).get()[1]\n",
    "    net.save_parameters('net.params')\n",
    "    print(\"EPOCH: [{}]: ; train loss: {}; train_acc: {}; val_acc: {}\".format(e, loss.mean().asscalar(), train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple Metrics\n",
    "- Often we would like to measure several metrics\n",
    "- An exaple is that correlation and MSE are combined for time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_results(data_loader, network):\n",
    "    metric_list = [mx.metric.MSE(), mx.metric.Accuracy(), mx.metric.PearsonCorrelation()]\n",
    "    metrics = mx.metric.CompositeEvalMetric()\n",
    "    for m in metric_list:\n",
    "        metrics.add(m)\n",
    "    \n",
    "    metrics.reset()\n",
    "    for i, (data, label) in enumerate(data_loader):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        outputs = network(data)\n",
    "        predictions = nd.argmax(outputs, axis=1)\n",
    "        metrics.update(preds=predictions, labels=label)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [0]:\n",
      "train loss: 0.9224110245704651\n",
      "training metrics: [('mse', 3.056719749466951), ('accuracy', 0.8114166666666667), ('pearsonr', 0.8213967369061631)]\n",
      "validation metrics: [('mse', 2.828223892405063), ('accuracy', 0.8202), ('pearsonr', 0.8348816169997487)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data_loader):\n",
    "        with autograd.record():\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            outputs = net(data)\n",
    "            loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "    train_acc = evaluate_results(train_data_loader, net)\n",
    "    val_acc = evaluate_results(val_data_loader, net)\n",
    "    \n",
    "    print(\"EPOCH: [{}]:\\ntrain loss: {}\".format(e, loss.mean().asscalar()))\n",
    "    print(\"training metrics: {}\".format(train_acc.get_name_value()))\n",
    "    print(\"validation metrics: {}\".format(val_acc.get_name_value()))\n",
    "    print('------------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Challenge\n",
    "- Try to rewrite the training code, using c conolutional network form the previous lab\n",
    "- beware that `gluon.nn.Conv2d()` supports NCHW’ and ‘NHWC’ layout for now. ‘N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and width dimensions respectively. Convolution is applied on the ‘H’ and ‘W’ dimensions. \n",
    "- We need to use `nd.transpose()` in order to change the layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('NEW: ', (1, 28, 28), 5.0), ('OLD: ', (28, 28, 1), 5.0))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(data, label):\n",
    "    return nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)\n",
    "\n",
    "train_dataset_conv = gluon.data.vision.MNIST(train=True, transform=transform)\n",
    "((\"NEW: \", train_dataset_conv[0][0].shape, train_dataset_conv[0][1]),\n",
    "(\"OLD: \", train_dataset[0][0].shape, train_dataset[0][1]))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
